{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6db4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,avg,round,filter\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark SQL\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60928500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\",True).parquet(r\"C:\\Users\\Admin\\Downloads\\csv_files\\titanic.parquet\")\n",
    "df.createOrReplaceTempView(\"passengers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09043e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+\n",
      "|Pclass|   Sex|SurvivalRate|\n",
      "+------+------+------------+\n",
      "|     1|female|        0.97|\n",
      "|     1|  male|        0.37|\n",
      "|     2|female|        0.92|\n",
      "|     2|  male|        0.16|\n",
      "|     3|female|         0.5|\n",
      "|     3|  male|        0.14|\n",
      "+------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 1: Survival Rate by Passenger Class and Gender. Calculate the survival rate grouped by Pclass and Sex. Sort the result by Pclass and descending survival rate.\n",
    "# Expected Output Columns: Pclass, Sex, SurvivalRate (rounded to 2 decimal places)\n",
    "\n",
    "# df_survival_rate = spark.sql(\"\"\"\n",
    "#                     SELECT Pclass, Sex, ROUND(AVG(Survived), 2) AS SurvivalRate\n",
    "#                     FROM passengers\n",
    "#                     GROUP BY Pclass, Sex\n",
    "#                     ORDER BY Pclass, SurvivalRate DESC\n",
    "#                 \"\"\"\n",
    "#                 )\n",
    "# df_survival_rate.show()\n",
    "\n",
    "# OR\n",
    "\n",
    "# df_survival_rate = df.groupBy(\"Pclass\", \"Sex\").agg(round(avg(\"Survived\"), 2).alias(\"SurvivalRate\")).orderBy(\"Pclass\", \"SurvivalRate\", ascending=[True, False])\n",
    "df_survival_rate = df.groupBy(\"Pclass\",\"Sex\").agg(round(avg(\"Survived\"), 2).alias(\"SurvivalRate\")).orderBy(col(\"Pclass\").asc(),col(\"SurvivalRate\").desc())\n",
    "df_survival_rate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b999f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+\n",
      "|Embarked|AvgFare|AvgAge|\n",
      "+--------+-------+------+\n",
      "|       Q|  13.28| 28.09|\n",
      "|    NULL|   80.0|  50.0|\n",
      "|       C|  59.95| 30.81|\n",
      "|       S|  27.08| 29.45|\n",
      "+--------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 2: Average Fare and Age by Embarkation Port. Find the average Fare and Age of passengers grouped by Embarked. Exclude rows where Fare or Age is NULL. Order by average fare descending.\n",
    "# Expected Output Columns: Embarked, AvgFare, AvgAge\n",
    "\n",
    "# df_average_fare = spark.sql(\"\"\"\n",
    "#                                 SELECT Embarked, ROUND(AVG(Fare), 2) AS AvgFare, ROUND(AVG(Age), 2) AS AvgAge\n",
    "#                                 FROM passengers\n",
    "#                                 WHERE Fare IS NOT NULL AND Age IS NOT NULL\n",
    "#                                 GROUP BY Embarked\n",
    "#                                 ORDER BY AvgFare DESC\n",
    "#                             \"\"\")\n",
    "# df_average_fare.show()\n",
    "\n",
    "# OR\n",
    "\n",
    "df_average_fare = df.groupBy(\"Embarked\").agg(round(avg(\"Fare\"),2).alias(\"AvgFare\"),round(avg(\"Age\"),2).alias(\"AvgAge\"))\n",
    "df_average_fare.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91198c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+------+------+--------+-----------+\n",
      "|Name                              |Pclass|Sex   |Fare    |Cabin      |\n",
      "+----------------------------------+------+------+--------+-----------+\n",
      "|Ward, Miss. Anna                  |1     |female|512.3292|NULL       |\n",
      "|Cardeza, Mr. Thomas Drake Martinez|1     |male  |512.3292|B51 B53 B55|\n",
      "|Lesurer, Mr. Gustave J            |1     |male  |512.3292|B101       |\n",
      "|Fortune, Miss. Mabel Helen        |1     |female|263.0   |C23 C25 C27|\n",
      "|Fortune, Miss. Alice Elizabeth    |1     |female|263.0   |C23 C25 C27|\n",
      "+----------------------------------+------+------+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Problem 3: Top 5 Paying Passengers Who Survived. Find the top 5 passengers (by Fare) who survived. Display their Name, Pclass, Sex, Fare, and Cabin.\n",
    "\n",
    "\n",
    "# df_survived = spark.sql(\"\"\"\n",
    "#                         SELECT Name, Pclass, Sex, Fare, Cabin\n",
    "#                         FROM passengers\n",
    "#                         WHERE Survived = 1\n",
    "#                         ORDER BY Fare DESC\n",
    "#                         LIMIT 5\n",
    "#                         \"\"\")\n",
    "# df_survived.show(truncate=False)\n",
    "\n",
    "# OR\n",
    "\n",
    "df_survived = df.select(\"Name\", \"Pclass\", \"Sex\", \"Fare\", \"Cabin\").filter(col(\"survived\")== 1).orderBy(col(\"Fare\").desc())\n",
    "df_survived.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a6caa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Statement:\n",
    "\n",
    "# You're tasked with identifying \"hidden gem\" startups from the attached CSVâ€” companies that are not heavily funded, but are showing strong performance metrics. Select companies that meet the following conditions:\n",
    "\n",
    "# -Have an ARR over $100M\n",
    "# -Have a Valuation under $500M\n",
    "# -Have a G2 Rating of 4.0 or above\n",
    "# -Were founded in or after 2015\n",
    "\n",
    "# You must:\n",
    "# 1)Group the results by Industry\n",
    "# 2)For each industry, calculate:\n",
    "# 3)The number of such companies\n",
    "# 4)The average ARR\n",
    "# 5)The average Valuation\n",
    "# 6)Sort the industries by average ARR descending\n",
    "\n",
    "# Display only industries that have at least 2 companies matching the above criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "359e41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(r\"C:\\Users\\Admin\\Downloads\\csv_files\\top_100_saas_companies_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e44dae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------------------+--------------------+-------------+------+---------+---------+--------------------+--------------------+---------+\n",
      "|Company Name|Founded Year|                  HQ|            Industry|Total Funding|   ARR|Valuation|Employees|       Top Investors|             Product|G2 Rating|\n",
      "+------------+------------+--------------------+--------------------+-------------+------+---------+---------+--------------------+--------------------+---------+\n",
      "|   Microsoft|        1975|    Redmond, WA, USA| Enterprise Software|          $1B| $270B|      $3T|  221,000|Bill Gates, Paul ...|Azure, Office 365...|      4.4|\n",
      "|  Salesforce|        1999|San Francisco, CA...|                 CRM|       $65.4M|$37.9B|  $227.8B|   75,000|Halsey Minor, Lar...|Sales Cloud, Serv...|      4.3|\n",
      "|       Adobe|        1982|   San Jose, CA, USA|   Creative Software|        $2.5M|$19.4B|    $240B|   29,945|   Hambrecht & Quist|Creative Cloud, D...|      4.5|\n",
      "|      Oracle|        1977|     Austin, TX, USA|Database & Enterp...|          $2K|$52.9B|    $350B|  143,000|Larry Ellison, Bo...|Oracle Cloud, Net...|      4.0|\n",
      "|         SAP|        1972|   Walldorf, Germany| Enterprise Software|          N/A|$32.5B|    $215B|  107,415|Dietmar Hopp, Kla...|S/4HANA, SuccessF...|      4.1|\n",
      "+------------+------------+--------------------+--------------------+-------------+------+---------+---------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_companies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ccc0cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Company Name', 'string'),\n",
       " ('Founded Year', 'int'),\n",
       " ('HQ', 'string'),\n",
       " ('Industry', 'string'),\n",
       " ('Total Funding', 'string'),\n",
       " ('ARR', 'string'),\n",
       " ('Valuation', 'string'),\n",
       " ('Employees', 'string'),\n",
       " ('Top Investors', 'string'),\n",
       " ('Product', 'string'),\n",
       " ('G2 Rating', 'double')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_companies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3213a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.createOrReplaceTempView(\"companies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04a1cdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------+-------------------+---------------+------------+---------+----------------------+\n",
      "|Company Name|ARR   |ARR_Clean|Valuation          |Valuation_clean|Founded Year|G2 Rating|Industry              |\n",
      "+------------+------+---------+-------------------+---------------+------------+---------+----------------------+\n",
      "|Microsoft   |$270B |270000.0 |$3T                |3000.0         |1975        |4.4      |Enterprise Software   |\n",
      "|Salesforce  |$37.9B|37900.0  |$227.8B            |227800.0       |1999        |4.3      |CRM                   |\n",
      "|Adobe       |$19.4B|19400.0  |$240B              |240000.0       |1982        |4.5      |Creative Software     |\n",
      "|Oracle      |$52.9B|52900.0  |$350B              |350000.0       |1977        |4.0      |Database & Enterprise |\n",
      "|SAP         |$32.5B|32500.0  |$215B              |215000.0       |1972        |4.1      |Enterprise Software   |\n",
      "|Intuit      |$14.4B|14400.0  |$180B              |180000.0       |1983        |4.4      |Financial Software    |\n",
      "|ServiceNow  |$8.9B |8900.0   |$147B              |147000.0       |2004        |4.4      |IT Service Management |\n",
      "|Workday     |$7.3B |7300.0   |$65B               |65000.0        |2005        |4.2      |HR & Finance          |\n",
      "|Zoom        |$4.5B |4500.0   |$85B               |85000.0        |2011        |4.5      |Video Communications  |\n",
      "|Shopify     |$7.1B |7100.0   |$95B               |95000.0        |2006        |4.4      |E-commerce            |\n",
      "|Atlassian   |$3.5B |3500.0   |$55B               |55000.0        |2002        |4.3      |Collaboration Software|\n",
      "|Snowflake   |$2.8B |2800.0   |$75B               |75000.0        |2012        |4.4      |Data Warehousing      |\n",
      "|HubSpot     |$2.2B |2200.0   |$32B               |32000.0        |2006        |4.4      |Marketing & Sales     |\n",
      "|DocuSign    |$2.5B |2500.0   |$10B               |10000.0        |2003        |4.5      |Digital Agreements    |\n",
      "|Slack       |$1.7B |1700.0   |$27.7B (Salesforce)|27700.0        |2009        |4.5      |Team Communication    |\n",
      "|Notion      |$400M |400.0    |$10B               |10000.0        |2013        |4.7      |Productivity          |\n",
      "|Datadog     |$2.1B |2100.0   |$44B               |44000.0        |2010        |4.4      |Monitoring & Analytics|\n",
      "|MongoDB     |$1.7B |1700.0   |$26B               |26000.0        |2007        |4.5      |Database              |\n",
      "|Okta        |$2.2B |2200.0   |$25B               |25000.0        |2009        |4.4      |Identity Management   |\n",
      "|Twilio      |$4.1B |4100.0   |$12B               |12000.0        |2008        |4.3      |Communications        |\n",
      "+------------+------+---------+-------------------+---------------+------------+---------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, when, avg, count\n",
    "\n",
    "df_cleaned = df_companies.withColumn(\n",
    "    \"Valuation_cleaned_raw\",\n",
    "    regexp_replace(col(\"Valuation\"), r\"\\(.*?\\)\", \"\")\n",
    ").withColumn(\n",
    "    \"ARR_cleaned_raw\",\n",
    "    regexp_replace(col(\"ARR\"), r\"\\(.*?\\)\", \"\")\n",
    ")\n",
    "\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    \"ARR_clean\",\n",
    "    when(col(\"ARR_cleaned_raw\").contains(\"B\"), regexp_replace(col(\"ARR_cleaned_raw\"), \"[$B]\", \"\").cast(\"double\") * 1000)\n",
    "    .otherwise(regexp_replace(col(\"ARR_cleaned_raw\"), \"[$M]\", \"\").cast(\"double\"))\n",
    ").withColumn(\n",
    "    \"Valuation_clean\",\n",
    "    when(col(\"Valuation_cleaned_raw\").contains(\"B\"), regexp_replace(col(\"Valuation_cleaned_raw\"), \"[$B]\", \"\").cast(\"double\") * 1000)\n",
    "    .when(col(\"Valuation_cleaned_raw\").contains(\"T\"), regexp_replace(col(\"Valuation_cleaned_raw\"), \"[$T]\", \"\").cast(\"double\") * 1000)\n",
    ")\n",
    " \n",
    "filtered = df_cleaned.filter(\n",
    "    (col(\"ARR_clean\") > 100) |\n",
    "    (col(\"Valuation_clean\") < 500) |\n",
    "    (col(\"G2 Rating\") >= 4.0) |\n",
    "    (col(\"Founded Year\") >= 2015)\n",
    ")\n",
    "\n",
    "\n",
    "final = filtered.select(\"Company Name\", \"ARR\",\"ARR_Clean\", \"Valuation\",\"Valuation_clean\", \"Founded Year\", \"G2 Rating\",\"Industry\")\n",
    "final.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c0f0c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------+------------+\n",
      "|           Industry|CompanyCount|  AvgARR|AvgValuation|\n",
      "+-------------------+------------+--------+------------+\n",
      "|Enterprise Software|           2|151250.0|    109000.0|\n",
      "|           Payments|           2| 16850.0|     75000.0|\n",
      "|      Cybersecurity|           2|  5300.0|     82500.0|\n",
      "|     Communications|           2|  3150.0|      8500.0|\n",
      "|     Data Analytics|           2|  2950.0|     40000.0|\n",
      "|      Cloud Storage|           2|  1750.0|      6000.0|\n",
      "|             Design|           2|  1300.0|     30000.0|\n",
      "|     Cloud Security|           2|  1050.0|     18750.0|\n",
      "|           Database|           2|   900.0|     14000.0|\n",
      "|    Work Management|           3|   756.0|      9300.0|\n",
      "|Customer Engagement|           2|   508.0|      5400.0|\n",
      "|             DevOps|           2|   422.5|      6850.0|\n",
      "|   Sales Engagement|           2|   200.0|      3350.0|\n",
      "|  Product Analytics|           2|   166.5|      2525.0|\n",
      "+-------------------+------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = final.groupBy(\"Industry\").agg(\n",
    "        count(\"*\").alias(\"CompanyCount\"),\n",
    "        avg(\"ARR_clean\").alias(\"AvgARR\"),\n",
    "        avg(\"Valuation_clean\").alias(\"AvgValuation\")\n",
    "    ).filter(col(\"CompanyCount\") >= 2).orderBy(col(\"AvgARR\").desc())\n",
    "\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33e291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
